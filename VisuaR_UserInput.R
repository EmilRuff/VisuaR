# #=== VisuaR Info ========================================================================================================================================================================
# # Workflow by Emil Ruff & Isabella Hrabe de Angelis 02/2025
# # Copyright Emil Ruff
# # The authors acknowledge valuable input by Alban Ramette and Angelique Gobet
# # Please cite https://github.com/EmilRuff/VisuaR

# #=== 1. User INPUT =====================================================================================================================================================================
# #=== 1.1. Mandatory INPUT ===============================================================================================================================================================
VisuaRProjectName="" # Give your analysis a (short) name
PathToVisuarOutput=file.path("")  # At this location the folder 'VisuaR' will be created containing sub-folders with your analyses (named as provided in VisuaRProjectname)

# # Provide your dada2 output
# # Used this pipeline for your dada2 analysis? https://astrobiomike.github.io/amplicon/dada2_workflow_ex#processing-with-dada2-in-r 
HappyBellydada2Input='N'          # set to 'Y' if you want to use the output generated from the happybelly workflow, set to 'N' if you want to use the output generated by the dada2-pipeline on the VisuaR github page

PathToSeqtabNochim=file.path("")  # provide the location and name of your seqtab_nochim.rds, e.g. C:/Users/User1/Desktop/ProjectName_seqtab_nochim.rds or ASVs_counts.tsv
PathToTaxonomy=file.path("")      # provide the location and name of your taxonomy.rds, e.g. C:/Users/User1/Desktop/ProjectName_taxa_species.rds or ASVs_taxonomy.tsv

# Analysis specifications ####
KingdomOfInterest='Bacteria|Archaea'  # Which kingdom are you interested in? choose Bacteria/Archaea/Eukaryota/All/Archaea|Bacteria...
MinimumAllowedReadCount=1000             # MinimumAllowedReadcount depends on the overall quality of the run and targeted sequencing depth and is used to remove samples with low reads (failed samples, controls). All samples with less reads than this number will be excluded from the analysis. This is based on all reads derived from your dada2 analysis, no matter which kingdom they belong to.
MinimumAllowedReadCount.Analysis=1000    # This field can be set to any number including 0 (zero) depending on which samples (based on read counts) should be included in the analysis. This happens after all ASVs and samples have been excluded as set in KeepSamplesbyName, excludeSamplesbyName, CladeOfInterest, ExcludeClade.

SaveWholeworkspace='Y'            # Set this variable to 'N' to save computational resources. R might run into memory issues if you have large datasets of e.g. 1000 samples. Set this variable to 'Y' to save all created tables in your workspace.

class.algorithm <- 'dada2' # dada2 or dec for dada2 or decipher algorithm used for taxonomy assignment
tax.database <- 'silva1381'  # database used for taxonomy assignment (for dada2: silva1381, silva138, silva132, rdp18, pr2, unite. for decipher: silva138, rdp18, pr2v4, unite2021.)
setM.minreads <- 'N' # set to a number if you want a specified M.minreads for subsampling for calculation of alpha diversity measures, otherwise set to "N"


# #=== 1.3. Optional INPUT - Sample selection - removal of selected samples =============================================================================================================================================
KeepSamplesbyName=''              # Enter names of samples that you want to keep. Leave blank to keep all samples. For an exact match use e.g. '^SampleName1$|^SampleName2$'. The use of general terms is possible too, e.g. 'control|blank|enrichment|cont|cntrl|enr|extrctrl|Control|Blank|Enrichment|Cont|Cntrl|Enr|Extrctrl'.

excludeSamplesbyName <- ""  # Enter names of samples that you want to exclude from your analysis. Leave blank to keep all samples. For an exact match use e.g. '^SampleName1$|^SampleName2$'. The use of general terms is possible too, e.g. 'control|blank|enrichment|cont|cntrl|enr|extrctrl|Control|Blank|Enrichment|Cont|Cntrl|Enr|Extrctrl'.

# #=== 1.4. Optional INPUT - Contextual data ==============================================================================================================================================
contextdata <- "Y" # Do you have contextual data? If not write 'N' , if yes write 'Y' and select a grouping category (Grouping1) as found in your contextdata header.

# # Useful notes on how to prepare your contextdata file:
# # replace missing values by NA
# # replace spaces or special symbols by underscores
# # use unique row names, rownames have to be exactly the same as your sample names from your sequencing files
# # dates: use 01/01/2016 instead of 01/01/16
# # do not start row or column names with a number
# # use a .txt file

contextdatafilepath=file.path("")  # provide the file path to your contextual data. e.g. 'C:/Users/User1/ProjectName_contextdata.txt'
sheetname <- "" # if an excel table provide the name of the sheet in the excel file.
excelstartrow <- 1 # only needed if input is an excel dataframe, set to 1 if you want to read in the whole file. 

# # The column in which the sample names in your contextual data match the sample names of your sequencing data
ColumnForMerging <- ""

# # The column of the sample names you want to be used in the analysis output
ColumnForAnalysisNames <- "" 

Grouping1 <- "" # groups in contextual data to be compared. E.g., air vs water.
Grouping2 <- "" # The samples within Grouping1 will be sorted using this continuous grouping parameter (e.g. concentration, depth profile) for visualization, smallest value is set first


ColumnOfVariableToExclude <- ""    # Enter column name where the VariableToExclude can be found. E.g. 'Temperature'
VariableToExclude <- ""            # Enter a contextual data variable to exclude. E.g. '4C'

ColumnOfVariableToKeep <- ""    # Enter column name where the VariableToKeep can be found. E.g. 'Temperature'
VariableToKeep <- ""            # Enter a contextual data variable to keep E.g. '4C'

CalculateIndicators <- "Y"          # If you have provided a Grouping 1 you can set this to 'Y' and VisuaR will calculate IndicatorSpecies on all taxonomic levels for you. Be aware that this might be time-consuming for a large dataset, if you are not interested in Indicator Species set it to 'N'
calcGroupedRaref <- "N"


# #=== 1.5. Specify VisuaR output =========================================================================================================================================================
NumberOfTOPClades <- 20      # Choose the number of most abundant clades that should be included in the relative abundance plot (bubbleplot). Remaining clades will be summed up and shown as 'Others'. A number between 10 and 30 is recommended.
NumberOfTOPClades.box <- 20  # Choose the number of most abundant clades that should be included in the relative abundance plot (boxplots). A number of 5 to 20 is recommended.
NumberOfWilcoxTtestClades <- 30 # Number or "all" Choose the number of clades you want to do wilcoxon test on. This takes quite long depending on your data

NI <- 10                     # number of iterations used for the calculation of alpha diversity indices (iterations will take long for big datasets, 10-50 are recommended based on number of samples analysed).

savenewseqtabandtax <- "N" # set to Y in case you want to save the subsetted seqtab and taxonomy file for future analyses, e.g. after contamination removal, to do a new analysis afterwards.

M.col <- c("")               # You can provide a color vector, e.g. c('blue','orange') or c('#CC79A7','#999999'). The vector needs as many colors as unique variables found in 'Grouping1'. The colors will be assigned to the Grouping1 variables in alphabetical order.

# #=== 1.2. Optional INPUT - Sample selection - removal of potential contaminants =============================================================================================================================================

CladeOfInterest <- ""                # Enter one or several clade(s) or keywords as found in your taxa.rds file, e.g. 'Desulfo|Meth'. Only keeps ASVs belonging to lineages containing the term 'Desulfo' and/or 'Meth', i.e. 'Methylococcus', 'Methylotenera'. use "^Methylotenera$|^Methylococcus$" for exact matches

ExcludeClade <- ""                   # Enter one or several clade(s) or keywords as found in your taxa.rds file. e.g. 'Escherichia|Salmonella'. Excludes ASVs belonging to lineages containing the term 'Escherichia' and/or 'Salmonella', i.e. Escherichia coli.

VisuaRContaminants <- "N" # (N: normal analysis). If set to Y this visualizes the "contaminant" fraction distinguished by the parameters set below. All ASVs/Reads which are not contaminants will be excluded from the analysis and only contaminants analyzed, to investigate potential sources.

removeContaminants <- ""         
# # Set to "remove" if you want to eliminate all ASVs which occur in your blanks. If you have more than one sample-blank group in your contextual data, only the ASVs occurring in the respective blank group will be eliminated from their sample group
# # set to "subtract-average" if you want to average the ASV counts in your controls and then subtract the average ASV count from your samples. If you provide sample-blank groupings below, the ASV counts of different controls will be averaged and then subtracted from the respective selection of samples (e.g. water controls get subtracted from water samples, air controls get subtracted from air samples)
# # set to "subtract-max" if you want to subtract the maximum read count occurring for the respective ASVs in the blanks from your samples instead of subtracting the average
# # set to "decontam" if you want to use the functions of the package "decontam" (https://github.com/benjjneb/decontam)
# # leave empty if you do not want to remove any potentially contaminant ASVs

# # if you want to normalize your read counts before removing/subtracting them set to Y (reads in samples are converted to frequencies by summing read counts per sample to 1)
normalizeMseqtax <- "N" # Y/N

# # add some probability testing
stat.test <- "N" # set to Y if you want to perform a statistical test before the ASVs are removed/subtracted. 
testtouse <- "w" # set to "w" to use wilcoxon test (does not assume normal distribution)
signiflevel <- 0.05

# # Provide a column defining blank batches (e.g. different sequencing runs) of blanks/samples
# # provide column name. Here groups should be defined (same index for samples and blanks that belong together) with grouping of samples (and blanks!)
# # also provide if all samples belong to the same blank set 
ColumnWithBlankGroupingSamples <- ""
ColumnWithBlankGrouping <- "" # column where the same grouping code as above is assigned to each blank belonging to the respective group (also if only one group!). All samples have to be set to NA in the contextual data

ASVcountInBlanksToExclude = 0 # Number of counts an ASV must occur in blanks (in average per blank). If set to 0, even if the ASV only occurs once in one blank it will be excluded/subtracted. If set to 1 or more, the ASV has to occur in average once in each blank to be excluded/subtracted.

# # If using package decontam
# # when using decontam you can include the DNA concentrations of samples and blanks.
### https://doi.org/10.1186/s40168-018-0605-2
# # for low-biomass samples 
decontam_isnotcontaminant <- "Y" # set to Y/N. Can't be used with IncludeDNAconc set to "Y" but works with batches
# # rest for decontam (DNA can't be included if low biomass analysis)
columnfordecontam <- "" # if using "decontam", define column in contextual data classifying samples with "FALSE" and blanks with "TRUE"
IncludeDNAconc <- "N"  # set to Y or N
columnwithDNAconcentrations <- "" # column in contextual data with DNA concentration
decontam.method <- "auto" # set to "auto", "frequency", "prevalence", "combined", "minimum", "either","both"

# # In case you want to save the decontaminated seqtab nochim and taxonomy table to continue working with that
SaveTables <- "Y"
